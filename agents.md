Do not add fallbacks without explicit authorization, prefer erroring out with a clean, well-described error so that it's clear what the system is doing.
Don't ever change the LLM or AI model without my authorization or try alternatives after a model been set by us.
Never ever ask me to run scripts or code, especially when the work is validation of your work. Run it yourself and review the output to ensure the work you performed is correct and delivers value to me.
Do not ever create any fake data unless explicitly authorized.